# lecture
    https://gfxcourses.stanford.edu/cs149/fall21/lecture/
    https://tschmidt23.github.io/cse599i/

# tool
    https://www.zotero.org/
    https://scholar.google.com/
    https://discourse.llvm.org/
    https://llvm.org/devmtg/2018-10/

--- 

# Conferences & Journals & Magazines & Thesis
    
## conference
    ICESS
    ICLR
    ICML
    ISCA
    KDD
    MAPL
    MAPS
    MICRO
    MOBO
    MLSys
    NeurIPS
    NIPS
    OOPSLA
    OSDI
    PACT
    PPoPP
    PLDI
    PSO    
    SCOPES
    SOSP
    SIGGRAPH
    Statistical science
    USENIX ATC
    VLDB

## Journals
    JPROC
    TACO
    TRETS
    TPDS

## Thesis

| no. | abbrev | name | publisher | website of proceedings | rank by ccf | domain | abstract submission ddl | full-text submission ddl | conference date |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|1	|PLDI|	ACM SIGPLAN Conference on Programming Language Design & Implementation | ACM |	https://dl.acm.org/conference/pldi/proceedings http://dblp.uni-trier.de/db/conf/pldi/ |	A |	Compiler and programming language	| |2021/11/19 | 2022/06/20|
|2	|POPL|	ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages|	ACM|	https://dl.acm.org/conference/popl/proceedings http://dblp.uni-trier.de/db/conf/IEEEpact/ http://dblp.uni-trier.de/db/conf/popl/|	A|	Compiler and programming language	| |2021/07/08 | 2022/01/16|
|3	|SOSP|	ACM Symposium on Operating Systems Principles|	ACM	|https://dl.acm.org/conference/sosp/proceedings http://dblp.uni-trier.de/db/conf/sosp/	|A|	Compiler and programming language|	2021/4/30|2021/05/07 | 2022/10/25|
|4|	OOPSLA|	Conference on Object-Oriented Programming Systems, Languages, and Applications|	ACM|	https://dl.acm.org/conference/splash/proceedings http://dblp.uni-trier.de/db/conf/oopsla/	|A|	Compiler and programming language|	|2021/04/16 | 2022/10/17|
|5|	OSDI|	USENIX Symposium on Operating Systems Design and Implementations|	USENIX|	https://www.usenix.org/conference/osdi21 http://dblp.uni-trier.de/db/conf/osdi/|	A	|Compiler and programming language	|2021/12/7|2021/12/04 | 2022/07/13|
|6|	CGO|	Code Generation and Optimization|	IEEE/ACM|	http://dblp.uni-trier.de/db/conf/cgo/ https://dl.acm.org/conference/cgo/proceedings	|B	|Compiler and programming language	|2021/8/27|2021/09/03 | 2022/02/12|
|7|	PACT|	International Conference on Parallel Architectures and Compilation Techniques	|IEEE/ACM	|https://dl.acm.org/conference/pact/proceedings http://dblp.uni-trier.de/db/conf/IEEEpact/	|B	|Compiler and programming language	|2021/4/15|2021/04/19 | 2022/09/26|
|8|	PPoPP|	ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming	|ACM|	http://dblp.uni-trier.de/db/conf/ppopp/ https://dl.acm.org/conference/ppopp/proceedings	|A	|Computer architecture and parallel computing|	2021/8/9|2021/08/13 | 2022/02/12|
|9|	ASPLOS|	International Conference on Architectural Support for Programming Languages and Operating Systems	|ACM	|http://dblp.uni-trier.de/db/conf/asplos/ https://dl.acm.org/conference/asplos/proceedings	|A	|Computer architecture and parallel computing	|2021/8/6|2021/08/06 | 2022/02/28|
|10|	ATC|	USENIX Annul Technical Conference	|USENIX	|https://www.usenix.org/conference/atc21 http://dblp.uni-trier.de/db/conf/usenix/index.html	|A	|Computer architecture and parallel computing	| |2021/01/12 | 2022/07/14|
|11|	MLSys|	Conference on Machine Learning and Systems	|	|https://mlsys.org/	|	|Machine learning	| |2021/01/17 | 2022/04/11|
|12|	NeurIPS|	Annual Conference on Neural Information Processing Systems|	MIT Press	|https://nips.cc/	|A	|Machine learning	|2021/5/19|2021/05/26 | 2022/12/06|
|13|	MAPL/MAPS|	Annual Symposium on Machine Programming	|ACM|	https://pldi20.sigplan.org/series/mapl|		|Machine learning	| |2021/04/10 | 2022/06/25|
|14|	ICLR|	International Conference on Learning Representations|	|	https://iclr.cc/ https://dblp.org/db/conf/iclr/index.html	|	|Machine learning	|2020/9/28|2021/10/02 | 2022/05/03|
|1A5	|MICRO|	Microprocessors and Microsystems: Embedded |Hardware Design	|
|1A7	|ASPLOS|	International Conference on Architectural Support for Programming Languages and Operating Systems |	| https://asplos-conference.org/2022/| Lausanne, Switzerland — Feb 28-March 4, 2022 |
|1A8	|ISCA|	International Symposium on Computer Architecture	|
|1A9	|USENIX ATC|	USENIX Annul Technical Conference	|
|2A1	|OSDI	|USENIX Symposium on Operating Systems Design and Implementations|	
|2A2	|PLDI	|ACM SIGPLAN Conference on Programming Language Design & Implementation	|
|2A3	|OOPSLA	|Conference on Object-Oriented Programming Systems, Languages, and Applications	|
|2A4	|SOSP	|ACM Symposium on Operating Systems Principles	|
|3A5	|NeurIPS	|Annual Conference on Neural Information Processing Systems	|
|3A6	|CVPR	|IEEE Conference on Computer Vision and Pattern Recognition	|
|4A7	|SIGGRPAH	|ACM SIGGRAPH Annual Conference	|
|1B5	|CGO	|Code Generation and Optimization	|
|1C4	|ASAP	|Application-Specific Systems, Architectures, and Processors| | https://www.asap2022.org/ |
|A	|TPDS	|IEEE Transactions on Parallel and Distributed Systems			|
|A	|Proc.IEEE	| Proceedings of the IEEE	|
|A	| IEEE | Institute of Electrical and Electronics Engineers | | https://ieeexplore.ieee.org/browse/periodicals/title | |
|A	| IEEE-HPEC | IEEE High Performance Extreme Computing Conference | | https://ieee-hpec.org/ | 19 - 23 September 2022 |
|A	| ESL | IEEE Embedded Systems Letters | |  https://ieee-ceda.org/publication/ieee-embedded-systems-letters-esl | ---- |	
|B	|TACO	|ACM Transactions on Architecture and Code Optimization			|
|B	|TRETS	|ACM Transactions on Reconfigurable Technology and Systems|
|B	| Addison-Wesley | Addison-Wesley Longman Publishing Co. ||  https://openlibrary.org/publishers/Addison_Wesley_Longman_Publishing_Co | ---- |
|B	| AHA | american heart association | | https://www.ahajournals.org/journal/str | ---- |
|A	| arXiv | ---- |  | https://arxiv.org/ | Cornell University |
|A	| AIS | association for information systems | | https://aisnet.org/ | AMCIS 2022: August 10-14, 2022; ICIS 2022: December 9-14, 2022 |

---

# SUMMARY
- survey
- libraries
- compiler
- tuner
- cost_model
- scheduler
- fusion
- architecture

## survey

no	title	year	conference/journal	authors	affiliation
sv01	The Deep Learning Compiler: A Comprehensive Survey	2020.8.28	TPDS	Mingzhen Li ; Yi Liu; XiaoYan Liu	Beihang University,Tsinghua University
sv02	An In-depth Comparison of Compilers for DeepNeural Networks on Hardware	2019.6	ICESS	Yu Xing; Jian Weng; Yushun Wang;	 Tsinghua University,Xilinx,Beijing National Research Center for Information Science and Technology
sv03	A Survey of Machine Learning for Big Code and Naturalness	2018.9	ACM Computing Surveys	Miltiadis Allamanis;Earl T. Barr;Premkumar Devanbu	Microsoft Research,University College London,University of California, Davis
sv04	A Survey on Compiler Autotuning using Machine Learning	2019.1	ACM Computing Surveys	Amir H. Ashouri;William Killian;John Cavazos	University of Toronto,Millersville University of Pennsylvania,University of Delaware
sv05	Machine Learning in Compiler Optimization	2018.1	 Proceedings of the IEEE	Zheng Wang; Michael O’Boyle	Lancaster University,University of Edinburgh
sv06	"Hardware Compilation of Deep Neural Networks:
An Overviewv"	2018.6	ASAP	Ruizhe Zhao, Shuanglong Liu, Ho-Cheung Ng	Imperial College London, London, United Kingdom
sv07	Survey of Machine Learning Accelerators	2020.9	IEEE-HPEC	Albert Reuther, Peter Michaleas, Michael Jones	MIT Lincoln Laboratory Supercomputing Center
sv08	"A Survey of FPGA-Based Neural Network Inference
Accelerator"	2018	Journal: TRETS	KAIYUAN GUO, SHULIN ZENG, JINCHENG YU	Tsinghua University
sv09	A Survey of Deep Learning: Platforms, Applications and Emerging Research Trends	2018		"
WILLIAM GRANT HATCHER AND WEI YU"	Department of Computer and Information Sciences, Towson University
sv10	Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey and Future Directions	2018.6	ACM Computing Surveys	STYLIANOS I. VENIERIS, ALEXANDROS KOURIS	Imperial College London
sv11	"High Performance Distributed Deep Learning:
A Beginner’s Guide"	2019.2	PPoPP	Dhabaleswar K. (DK) Panda,Ammar Ahmad Awan,Hari Subramoni	The Ohio State University


## libraries

GPUs			
Nvidia	Ampere architecture white paper.	2022	https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf
Nvidia	Turing architecture white paper.	2022	https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf
Nvidia	Volta architecture white paper.	2022	https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf
Nvidia	CuBLAS.	2022	https://developer.nvidia.com/cublas
Nvidia	CuDNN.	2022	https://developer.nvidia.com/cudnn
Nvidia	CUTLASS.	2022	https://github.com/NVIDIA/cutlass
Nvidia	Deep Learning Performance Guide. 	2022	https://docs.nvidia.com/deeplearning/performance/dl-performance-convolutional/index.html
			
			
CPUs			
Intel	oneAPI Deep Neural Network Library. 	2022	https://github.com/oneapi-src/oneDNN
mit	VeGen: a vectorizer generator for SIMD and beyond	2021	https://groups.csail.mit.edu/commit/papers/2021/vegen.pdf
			
			
TPU			
Google.	XLA: Domain-specific compiler for linear algebra to optimize tensorflow computations	2022	https://www.tensorflow.org/xla/jit


## compiler

no	title	abbreviation	year	conference/journal	authors	affiliation
cp01	DeepCuts: A Deep Learning Optimization Framework for Versatile GPU Workloads	DeepCuts	2021/6	PLDI	Wookeun Jung, Thanh Tuan Dao, Jaejin Lee	Seoul National University
cp02	PET: Optimizing Tensor Programs with Partially Equivalent Transformations and Automated Corrections	PET	2021/7	OSDI	Haojie Wang, Jidong Zhai, Mingyu Gao, 	Tsinghua University,Carnegie Mellon University,Facebook
cp03	MLIR: Scaling Compiler Infrastructure for Domain Specific Computation	MLIR	2021/2	CGO	Chris Lattner, Mehdi Amini, Uday Bondhugula	Google,Indian Institute of Science
cp04	A Tensor Compiler for Unified Machine Learning Prediction Serving	Hummingbird	2020	OSDI	Supun Nakandala; Karla Saur; Gyeong-In Yu	UC San Diego;  Microsoft; Seoul National University
cp05	Rammer: Enabling Holistic Deep Learning Compiler Optimizations with rTasks	Rammer/nnfusion	2020	OSDI	Lingxiao Ma,Zhiqiang Xie, Zhi Yang	Peking University and Microsoft Research;ShanghaiTech University and Microsoft Research; Peking University
cp06	MLIR: A Compiler Infrastructure for the End of Moore's Law	MLIR	2020/5	CGO	Chris Lattner,Mehdi Amini,Uday Bondhugul	Google,IISc
cp07	TASO: Optimizing Deep Learning Computation with Automatic Generation of Graph Substitutions	TASO	2019/1	SOSP	Zhihao Jia，Oded Padon，James Thomas	Stanford University
cp08	Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code	Tiramisu	2019	CGO	Riyadh Baghdadi, Jessica Ray, Malek Ben Romdhane	MIT
cp09	Triton: an intermediate language and compiler for tiled neural network computations	Triton	2019/6	MAPL	Philippe Tillet,H. T. Kung,David Cox	Harvard University
cp10	Relay: A High-Level Compiler for Deep Learning	Relay	2019/8		Jared Roesch, Steven Lyubomirsky, Marisa Kirisame	Paul G. Allen School of Computer Science & Engineering University of Washington
cp11	TVM: An Automated End-to-End Optimizing Compiler for Deep Learning	TVM	2018/10	OSDI	Tianqi Chen,Thierry Moreau,  Ziheng Jiang	University of Washington
cp12	Tensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions	TC	2018/6	Facebook AI Research Technical Report	Nicolas Vasilache, Oleksandr Zinenko, Theodoros Theodoridis	Facebook AI Research,Inria & ENS, ETH Zurich
cp13	Intel nGraph: An Intermediate Representation, Compiler, and Executor for Deep Learning	nGraph	2018/1	SYSML	Scott Cyphers, Arjun K. Bansal, Anahita Bhiwandiwalla,	Intel
cp14	Glow: Graph Lowering Compiler Techniques for Neural Networks	Glow	2018/5		Nadav Rotem, Jordan Fix, Saleem Abdulrasool	Facebook
cp15	"DLVM: A modern compiler infrastructure for deep learning systems/DLVM: A modern compiler framework for neural
network DSLs"	DLVM	2018/2	NIPS	Richard Wei,Lane Schwartz,Vikram Adve	Departments of Computer Science & Linguistics University of Illinois at Urbana-Champaign
cp16	Diesel: DSL for linear algebra and neural net computations on GPUs	Diesel	2018/6	MAPL 	Venmugil Elango,Norm Rubin,Mahesh Ravishankar	Nvidia
cp17	The Tensor Algebra Compiler 	TACO	2017/10	OOPSLA 	Fredrik Kjolstad,Shoaib Kamil,Stephen Chou	Massachusetts Institute of Technology,Adobe,
cp18	Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines 	Halide	2013/6	PLDI	Jonathan Ragan-Kelley,Connelly Barnes,Andrew Adams	MIT CSAIL,Adobe
cp19	AKG: automatic kernel generation for neural processing units using polyhedral transformations	AKG	2021/6	PLDI	 Jie Zhao,Bojie Li,Wang Nie	State Key Laboratory of Mathematical Engineering and Advanced Computing, China;Huawei Technologies
cp20	 Tensorflow: A system for large-scale machine learning.	Tensorflow	2016	OSDI	Martín Abadi, Paul Barham, Jianmin Chen	Google Brain
cp21	Nvidia: TensorRT; Google:TOCO;Tensorflow:XLA					
cp22	LLVM: A compilation framework for lifelong program analysis & transformation	LLVM	2004	CGO	Chris Lattner, Vikram Adve	University of Illinois at Urbana-Champaign
cp23	Bridge the Gap between Neural Networks and Neuromorphic Hardware with a Neural Network Compiler		2018/5	ASPLOS	Yu Ji,Youhui Zhang,Wenguang Chen	Tsinghua University, Beijing, China
cp24	Cortex: A Compiler for Recursive Deep Learning Models	Cotex	2021	MLSys	Pratik Fegade, Tianqi Chen, Phillip Gibbons	Carneige Mellon University; 
cp25	IGC: The Open Source Intel Graphics Compiler	IGC	2019	CGO	Anupama Chandrasekhar, Gang Chen, Po-Yu Chen	Intel Corporation
cp26	Cavs: An Efficient Runtime System for Dynamic Neural Networks	Cavs	2018	ATC	Shizhen Xu,Hao Zhang,Graham Neubig	CMU,Tsinghua University
cp27	Locus: A System and a Language for Program Optimization	Locus	2019	CGO	Thiago S. F. X. Teixeira, Corinne Ancourt, David Padua	MINES ParisTech, PSL University, France
cp28	Super-Node SLP: Optimized Vectorization for Code Sequences Containing Operators and Their Inverse Elements	SNSLP	2019	CGO	Vasileios Porpodas ,Rodrigo C. O. ,Rocha Evgueni Brevno	Intel Corporation,University of Edinburgh, UK
cp29	Transferable Graph Optimizers for ML Compilers		2020	NIPS	Yanqi Zhou, Sudip Roy, Amirali Abdolrashidi	Google
cp30	Compiling Halide Programs to Push-Memory Accelerators	halide	2021	ArXiv	"Qiaoyi Liu, Dillon Huff, Jeff Setter, Maxwell Strange, Kathleen Feng, Kavya Sreedhar, Ziheng Wang,
Keyi Zhang, Mark Horowitz, Priyanka Raina, and Fredrik Kjolstad"	Stanford
cp31	A practical automatic polyhedral parallelizer and locality optimizer	polyhedral	2008	ACM	Uday Bondhugula, Albert Hartono, J. Ramanujam, P. Sadayappan	The Ohio State University, Louisiana State University
cp32	isl. An Integer Set Library for the Polyhedral Model	isl	2010	icms	Sven Verdoolaege	cs.kuleuven.be,inria.fr
cp33	Polyhedral parallel code generation for CUDA	taco	2013	ACM	Sven Verdoolaege, Juan Carlos Juega, Albert Cohen, José Ignacio Gómez, Christian Tenllado, Francky Catthoor, Authors Info & Claims	INRIA and Ecole Normale Superieure, Universidad Complutense de Madrid
cp34	Stripe: Tensor Compilation via the Nested Polyhedral Model	Stripe	2019	ArXiv	Tim Zerrell, Jeremy Bruestle	Intel
cp35	PolyDL: Polyhedral Optimizations for Creation of High-performance DL Primitives	PolyDL	2021	ArXiv	Sanket Tavarageri, Alexander Heinecke, Sasikanth Avancha, Gagandeep Goyal, Ramakrishna Upadrasta, Bharat Kaul	Intel Labs
cp36	ISA mapper: a compute and hardware agnostic deep learning compiler	ISA mapper	2019	SysML	Matthew Sotoudeh, Anand Venkat, Michael Anderson, Evangelos Georganas, Alexander Heinecke, Jason Knight	University of California, Intel
cp37	UNIT: Unifying Tensorized Instruction Compilation	UNIT	2021	IEEE	Jian Weng, Animesh Jain, Jie Wang, Leyuan Wang, Yida Wang, Tony Nowatzki	University of California, Los Angeles, Amazon



## tuner

no	title	abbreviation	year	conference/journal	authors	affiliation
tn01	Learning to Optimize Tensor Programs	autoTVM	2018	NeurIPS	Tianqi Chen, Lianmin Zheng, Eddie Yan	"University of Washington
Shanghai Jiao Tong University"
tn02	"AdaTune: Adaptive Tensor Program Compilation
Made Efficient"	AdaTune	2020	NeurIPS	Menghao Li, Minjia Zhang,Chi Wang	Microsoft Corporation
tn03	"Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation
"	Chameleon	2020.1	ICLR	Byung Hoon Ahn, Prannoy Pilligundla, Amir Yazdanbakhsh	University of California,Google
tn04	Reinforcement Learning and Adaptive Sampling for Optimized DNN Compilation	Chameleon	2019.5	ICML	Byung Hoon Ahn,Prannoy Pilligundla, Hadi Esmaeilzadeh	University of California, San Diego, California, USA
tn05	Polyhedra scanning revisited		2012.6	PLDI	Chun Chen	University of Utah, Salt Lake City, UT, USA
tn06	Optimizing {CNN} Model Inference on CPUs		2019	USENIX ATC	Yizhi Liu, Yao Wang, Ruofei Yu	Amazon Web Services
tn07	Machine Learning in Compiler Optimization		2018.1	JPROC	Zheng Wang and Michael O’Boyle	Lancaster University,, University of Edinburgh
tn08	Bliss: auto-tuning complex applications using a pool of diverse lightweight learning models	Bliss	2021/6	PLDI	Rohan Basu Roy,Tirthak Patel,Vijay Gadepally	Northeastern University, USA
tn09	ApproxTuner: a compiler and runtime system for adaptive approximations	ApproxTuner	2021	PPoPP	Hashim Sharif, Yifan Zhao, Maria Kotsifakou	
tn10	I/O lower bounds for auto-tuning of convolutions in CNNs		2021	PPoPP	Xiaoyang Zhang ,Junmin Xiao ,Guangming Tan 	Institute of Computing Technology, Chinese Academy of Sciences,
tn11	"	GPTune: Multitask Learning for Autotuning Exascale Applications"	GPTune	2021	PPoPP	Yang Liu,Wissam Sid-Lakhdar,Osni Marques	Berkeley Laboratory
tn12	DYNATUNE: Dynamic Tensor Program Optimization in Deep Neural Network Compilation	DYNATUNE	2021	ICLR 	Minjia Zhang, Menghao Li, Chi Wang & Mingqin Li	Microsoft Corporation


## cost_model

no	title	abbreviation	year	conference/journal	authors	affiliation
cm01	A Deep Learning Based Cost Model for Automatic Code Optimization in Tiramisu		2020/10	Graduation Thesis	"Massinissa Merouani,Mohamed-Hicham Leghettas,Riyadh Baghdadi

"	"Ecole Nationale Supérieure d'Informatique,Massachusetts Institute of Technology

"
cm02	A Deep Learning Based Cost Model for Automatic Code Optimization		2021	MLSys	Riyadh Baghdadi, Massinissa Merouani,Mohamed-Hicham Leghettas	Massachusetts Institute of Technology,New York University Abu Dhabi,Ecole Nationale Superieure d’Informatique
cm03	A Learned Performance Model for Tensor Processing Units		2021	MLSys	Samuel J. Kaufman, Phitchaya Mangpo Phothilimthana,Yanqi Zhou	Google, Paul G. Allen School of Computer Science & Engineering, University of Washington
cm04	MetaTune: Meta-Learning Based Cost Model for Fast and Efficient Auto-tuning Frameworks	MetaTune	2021/9	arXiv	Jaehun Ryu, Hyojin Sung	Pohang University of Science and Technology, Pohang
cm05	Learned TPU Cost Model for XLA Tensor Programs		2019	NIPS	Samuel Kaufman, Phitchaya Mangpo Phothilimthana,Mike Burrows	University of Washington, Google Brain
cm06	Predictive Data Locality Optimization for Higher-Order Tensor Computations		2021	MAPS	Tharindu Patabandi, Anand Venkat, Abhishek Kulkarni	University of Utah Salt Lake City, UT, USA;Intel Labs;Intel Corporation Santa Clara, CA, USA
cm07	Analytical characterization and design space exploration for optimization of CNNs		2021/4	ASPLOS	Rui Li,Yufan Xu, Aravind Sukumaran-Rajam	University of Utah, USA;Washington State University, USA
cm08	Simulating Execution Time of Tensor Programs using Graph Neural Networks		2019	ICLR	Jakub M. Tomczak, Romain Lepert, Auke Wiggers	Qualcomm AI Research



## scheduler

no	title	abbreviation	year	conference/journal	authors	affiliation
sd01	Value Learning for Throughput Optimization of Deep Neural Networks		2021/9	MLSys	Benoit Steiner, Chris Cummins, Horace He	facebook
sd02	Ansor : Generating High-Performance Tensor Programs for Deep Learning	Ansor	2020/6	OSDI	Lianmin Zheng, Chengfan Jia, Minmin Sun	UC Berkeley, Alibaba Group, Amazon Web Services
sd03	Schedule Synthesis for Halide Pipelines on GPUs		2020/8	TACO	Savvas Sioutas,Sander Stuijk,Twan Basten	Eindhoven University of Technology, Eindhoven, The Netherlands
sd04	Ordering Chaos: Memory-Aware Scheduling of Irregularly Wired Neural Networks for Edge Devices	Ordering Chaos	2020/5	MLSys	Byung Hoon Ahn,Jinwon Lee,Jamie Menjay Lin	"University of
California, San Diego 2Qualcomm AI Research 3Duke University"
sd05	FlexTensor: An Automatic Schedule Exploration and Optimization Framework for Tensor Computation on Heterogeneous System	FlexTensor	2020/3	ASPLOS	Size Zheng，Yun Liang， Shuo Wang	Peking University
sd06	Optimizing the Memory Hierarchy by Compositing Automatic Transformations on Computations and Data		2020	MICRO	Jie Zhao,Peng Di	"State Key Laboratory of Mathematical Engineering
and Advanced Computing; Huawei Technologies"
sd07	Learning to Optimize Halide with Tree Search and Random Programs		2019	SIGGRAPH	 Andrew Adams,Karima Ma,Luke Anderson	Facebook AI Research,UC Berkeley,MIT CSAIL
sd08	Automatically Scheduling Halide Image Processing Pipelines		2016	SIGGRAPH	Ravi Teja Mullapudi,Andrew Adams,Dillon Sharlt, 	CMU,Google
sd09	Automatic Generation of Multi-Objective Polyhedral Compiler Transformations		2020/9	PACT	Lorenzo Chelini, Tobias Gysi,Tobias Grosser	Eindhoven University of Technology; ETH Zurich, Zurich, Switzerland
sd10	Efficient automatic scheduling of imaging and vision pipelines for the GPU		2021,10	OOPSLA	Luke Anderson, Andrew Adams, Karima Ma	MIT,Adobe
sd11	COLAB: a collaborative multi-factor scheduler for asymmetric multicore processors	COLAB	2020	CGO	Teng Yu，Pavlos Petoumenos	University of St Andrews
sd12	Interstellar: Using Halide's Scheduling Language to Analyze DNN Accelerators					
sd13	ProTuner: Tuning Programs with Monte Carlo Tree Search	ProTuner	2020.5	arXiv	Ameer Haj-Ali, Hasan Genc, Qijing Huang	UC Berkeley
sd14	Polyhedral auto-transformation with no integer linear programming		2018/6	PLDI	Aravind Acharya, Uday Bondhugula,Albert Cohen 	Indian Institute of Science, India; Inria, France / ENS, France
sd11	Composable, sound transformations of nested recursion and loops		2019/6	PLDI	Kirshanthan Sundararajah,Milind Kulkarni	Purdue University, USA
sd13	Learning to Make Compiler Optimizations More Effective		2021/2	MAPS	Rahim Mammadli, Marija Selakovic, Felix Wolf,	Department of Computer ScienceTechnical University of Darmstadt
sd15	Loop Transformations Leveraging Hardware Prefetching					
sd16	TENET: A Framework for Modeling Tensor Dataflow Based on Relation-Centric Notation	TENET	2021	ISCA		Peking University
sd17	Differentiable programming for image processing and deep learning in halide		2018	ACM	TZU-MAO LI, MICHAËL GHARBI, ANDREW ADAMS, FRÉDO DURAND, JONATHAN RAGAN-KELLEY	MIT CSAIL, Facebook AI Research, UC Berkeley & Google
sd18	ALT: Optimizing Tensor Compilation in Deep Learning Compilers with Active Learning	ALT	2020	IEEE	Xi Zeng; Tian Zhi; Zidong Du; Qi Guo; Ninghui Sun; Yunji Chen	Hartford, CT, USA
sd19	Rammer: Enabling Holistic Deep Learning Compiler Optimizations with rTasks	Rammer	2020	USENIX	Lingxiao Ma, Zhiqiang Xie, Zhi Yang, Jilong Xue,  Youshan Miao, Wei Cui, Wenxiang Hu, Fan Yang, Lintao Zhang,  Lidong Zhou	Peking University, ShanghaiTech University,  Microsoft Research
sd20	NeoFlow: A Flexible Framework for Enabling Efficient Compilation for High Performance DNN Training	NeoFlow	2021	IEEE	Size Zheng, Student Member, IEEE, Renze Chen, Yicheng Jin, Anjiang Wei, Bingyang Wu, Xiuhong Li, Shengen Yan, Yun Liang	Peking, Beijing
sd21	TensorIR: An Abstraction for Automatic Tensorized Program Optimization	TensorIR	2022    arxiv   Siyuan Feng, Bohan Hou, Hongyi Jin, Wuwei Lin, Junru Shao, Ruihang Lai, Zihao Ye, Lianmin Zheng, Cody Hao Yu, Yong Yu, Tianqi Chen  Shanghai Jiao Tong University
sd22	Tensor Program Optimization with Probabilistic	Meta-schedule	2022/10/09    arxiv   Junru Shao, Xiyou Zhou, Siyuan Feng, Bohan Hou, Ruihang Lai, Hongyi Jin, Wuwei Lin, Masahiro Masuda, Cody Hao Yu, Tianqi Chen  Shanghai Jiao Tong University,CMU,OctoML

## fusion

no	title	abbreviation	year	conference/journal	authors	affiliation
fs01	DNNFusion: Accelerating Deep Neural Networks Execution with Advanced Operator Fusion	DNNFusion	2020/9	arXiv	Zhen Zheng, Pengzhan Zhao, Guoping Long	Alibaba Group
fs02	Automatic Kernel Fusion for Image Processing DSLs		2017/7	CVPR	Fisher Yu Dequan Wang Evan Shelhamer	UC Berkeley
fs03	From Loop Fusion to Kernel Fusion: A Domain-Specific Approach to Locality Optimization		2021/8	PLDI	Wei Niu,Jiexiong Guan,Yanzhi Wang	William & Mary, USA;Northeastern University, USA
fs04	FusionStitching:Deep Fusion and code generation for Tensorflow computation on GPUs		2020/7	arXiv	Ao Li,Bojian Zheng,Gennady Pekhimenko	University of Toronto
fs05	FusionStitching: Boosting Execution Efficiency of Memory Intensive Computations for DL Workloads		2019/11	ISBN	Guoping Long, J. Yang, Wei Lin	Alibaba Group
fs06	FusionStitching: Boosting Memory Intensive Computations for Deep Learning Workloads		2018/11	axXiv	Guoping Long,Jun Yang, Kai Zhu	Alibaba Group
fs07	Automatic Horizontal Fusion for GPU Kernels			VLDB Endowment	, Berthold Reinwald,Dylan Hutchison	IBM Research , University of Washington
fs08	On Optimizing Operator Fusion Plans for Large-Scale Machine Learning in SystemML		2019.2	CGO	Bo Qiao, Oliver Reiche, Frank Hannig	FAU, Germany
fs09	Optimizing CUDA code by kernel fusion—Application on BLAS		2018	SCOPES	Bo Qiao, Oliver Reiche, Frank Hannig	FAU,Germany
fs10	Kernel Weaver: Automatically Fusing Database Primitives for Efficient GPU Computation		2015			
fs11	On Optimizing Machine Learning Workloads via Kernel Fusion (这篇讲了对sparse/dense的处理)		2021	DBLP	Minjia Zhang, Menghao Li, Chi Wang, Mingqin Li	microsoft
fs12	Scalable Kernel Fusion for Memory-Bound GPU Application					
fs13	Understanding GNN computational Graph: A coordinated computation, IO, And Memory Perspective					


## search

no	title	abbreviation	year	conference/journal	authors	affiliation
sm01	Simulated annealing		1993	Statistical science	Dimitris Bertsimas, John Tsitsiklis	
sm02	Genetic Algorithms in Search, Optimization and Machine Learning		1989	Addison-Wesley Longman Publishing Co.	David E. Goldberg	
sm03	"N. Hansen, “The CMA evolution strategy: a comparing review,” in
Towards a new evolutionary computation. Springer, 2006, pp. 75–102."	evolutionary	2006			
sm04	"Nikolaus Hansen. 2006. The CMA evolution strategy: a comparing review. In
Towards a new evolutionary computation. Springer, 75–102."	covariance matrix adaptation evolution strategy (cma-es)	2006			
sm05	"Christopher C Cox. 2017. A Comparison of Active and Passive Portfolio Management.
(2017)"	passive portfolio	2017			
sm06	"John H Holland. 1992. Genetic algorithms. Scientific american 267, 1 (1992),
66–73."	genetic algorithm	1992			
sm07	"Kenneth V Price. 2013. Differential evolution. In Handbook of Optimization.
Springer, 187–214."	differntial evlotuon	2013			
sm08	"Ingo Rechenberg. 1994. Evolutionsstrategie: Optimierung technischer Systeme
nach Prinzipien der biologischen Evolution. frommann-holzbog, Stuttgart, 1973.
Step-Size Adaptation Based on Non-Local Use of Selection Information. In PPSN3
(1994)."	1+lambda-es	1994			
sm09	"Michael Hellwig et al. 2016. Evolution under strong noise: A self-adaptive
evolution strategy can reach the lower performance bound-the pccmsa-es. In
International Conference on PPSN3. Springer, 26–36."	test-based population size adpatation	2016			
sm10	"James Kennedy et al. 1995. Particle swarm optimization. In ICNN, Vol. 4. IEEE,
1942–1948."		1995			
sm11	"Eric Schkufza et al. 2013. Stochastic superoptimization. ACM SIGARCH Computer
Architecture News 41, 1 (2013), 305–316."	random search	2013	
sm12	One-shot tuner for deep learning compilers	One-shot	2022	ACM	Jaehun Ryu, Eunhyeok Park, Hyojin Sung	POSTECH
sm13	Meta-Learning in Neural Networks: A Survey	Meta-Learning	2022	IEEE	Timothy Hospedales , Antreas Antoniou, Paul Micaelli, and Amos Storkey	Samsung


## convolution
no	title	abbreviation	year	conference/journal	authors	affiliation
co1	Winograd Algorithm for AdderNet		2021/9	MLSys	Benoit Steiner, Chris Cummins, Horace He	facebook
co2	EFFICIENT WINOGRAD CONVOLUTION VIA INTEGER ARITHMETIC					
co3	AMOS: Enabling Automatic Mapping for Tensor Computations On Spatial Accelerators with Hardware Abstraction 	AMOS
co4	Accelerating Reduction and Scan Using Tensor Core Units					
co5	Parallel convolution processing using an integrated photonic tensor core					
co6	NVIDIA Tensor Core Programmability,Performance,Precision					
co7	Optimizing the Fast Fourier Transform using Mixed Precision on Tensor Core Hardware					
co8	Efficient Tensor Cores support in TVM for Low-Latency Deep learning		2021			
co9	Kernel Operations on the GPU, with Autodiff without Memory Overflows		2021			
co10	AutoGTCO: Graph and Tensor Co-Optimize for Image Recognition with Transformers on GPU					
co11	Programming Tensor Cores from an Image Processing DSL		2020			
co12	Efficient Execution of Quantized Deep Learning Models: A Compiler Approach		2020			
co13	Agile Autotuning of a Transprecision Tensor Accelerator Overlay for TVM Compiler Stack		2020			
co14	Extending Tensor Virtual Machine to Support Deep-Learning Accelerators with Convolution Cores		2022			



## architecture

no	title	abbreviation	year	conference/journal	authors
ar1	Tactics to directly map CNN graphs on embedded FPGAs		2017	 IEEE Embedded Systems Letters	Kamel Abdelouahab, Maxime Pelcat, Jocelyn Serot
ar2	Google’s Training Chips Revealed: TPUv2 and TPUv3				Thomas Norrie, Nishant Patil, Doe Hyun Yoon
ar3	Scalable multi-chip-module-based deep neural networ accelerator designed with a high-productivity vlsi methodology				Rangharajan Venkatesan, Yakun Sophia Shao, Brian Zimmer
ar4	Wafer-Scale Deep Learning				
ar5	"Multi-Million Core,
Multi-Wafer AI Cluster"				
ar6	Aquabolt-XL: Samsung HBM2-PIM with in-memory processing for ML accelerators and beyond 	Aquabolt-XL			Jin Hyun Kim, Shin-haeng Kang, Sukhan Lee
ar7	timeloop.a systematic approach to DNN accelerator evaluation	timeloop	2019.	IEEE	Angshuman Parashar; Priyanka Raina; Yakun Sophia Shao; Yu-Hsin Chen; Victor A. Ying; Anurag Muk
ar8	dMazeRunner: Executing Perfectly Nested Loops on Dataflow Accelerators	dMazeRunner	2019	ACM	 SHAIL DAVE, YOUNGBIN KIM, SASIKANTH AVANCHA, KYOUNGWOO LEE, AVIRAL SHRIVASTAVA
ar9	CoSA: Scheduling by Constrained Optimization for Spatial Accelerators	CoSA	2021	 Human-Computer Interaction	Qijing Huang, Minwoo Kang, Grace Dinh, Thomas Norell, Aravind Kalaiah, James Demmel, John Wawrzynek, Yakun Sophia Shao
ar10	SARA: Scaling a Reconfigurable Dataflow Accelerator	SARA	2021	ACM/IEEE	Yaqi Zhang; Nathan Zhang; Tian Zhao; Matt Vilim; Muhammad Shahbaz; Kunle Olukotun
ar11	HASCO: Towards Agile HArdware and Software CO-design for Tensor Computation	HASCO	2021	IEEE	Qingcheng Xiao, Size Zheng, Bingzhe Wu, Pengcheng Xu, Xuehai Qian, Yun Liang
ar12	Chip Placement with Deep Reinforcement Learning	Chip_Placement	2020	arXiv	zalia Mirhoseini, Anna Goldie, Mustafa Yazgan, Joe Jiang, Ebrahim Songhori, Shen Wang, Young-Joon Lee, Eric Johnson, Omkar Pathak, Sungmin Bae, Azade Nazi, Jiwoo Pak, Andy Tong, Kavya Srinivasa, William Hang, Emre Tuncer, Anand Babu, Quoc V. Le, James Laudon, Richard Ho, Roger Carpenter, Jeff Dean